{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##luigi-vars\n",
    "NCPU = 8\n",
    "RAW_HD5 = '/nbi/group-data/ifs/JIC/Research-Groups/Diane-Saunders/FP_pipeline/data/0.1/Callset/callsets/2014/2014_raw.hd5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import vcfnp\n",
    "import numpy as np\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import allel\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import dask.array as da\n",
    "from dask.diagnostics import ProgressBar,  Profiler, ResourceProfiler, CacheProfiler, visualize\n",
    "from bokeh.io import output_notebook\n",
    "\n",
    "import qgrid\n",
    "qgrid.nbinstall(overwrite=True)  # copies javascript dependencies to your /nbextensions folder\n",
    "\n",
    "output_notebook()\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (12,8)\n",
    "sns.set_style('white')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "callset = h5py.File(RAW_HD5, mode='r')\n",
    "calldata = callset['calldata']\n",
    "\n",
    "samples = list(callset['samples'])\n",
    "genotypes = allel.GenotypeChunkedArray(callset['calldata']['GT'])\n",
    "variants = allel.VariantChunkedTable(callset['variants'])\n",
    "\n",
    "is_snp = variants.is_snp[:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "called = genotypes.is_called().sum(axis=0)\n",
    "het = genotypes.is_het().sum(axis=0)\n",
    "hom_alt = genotypes.is_hom_alt().sum(axis=0)\n",
    "ref = genotypes.is_hom_ref().sum(axis=0)\n",
    "var_frac = 1 - (ref/called)[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "summary = pd.DataFrame(np.array([called, het, hom_alt, ref, 1000*var_frac]).T, \n",
    "                       columns=['Called', 'Het', 'Hom Alt', 'Hom Ref', 'Variants/kbp'],\n",
    "                       index=samples)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "qgrid.show_grid(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Heterozygosity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.scatter(called, het, label=\"Het sites\")\n",
    "plt.scatter(called, hom_alt, c='red', label=\"Hom Alt site\")\n",
    "plt.ylabel(\"Called Site\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Covariation of site level statisitics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def hexbin(x, y, color, **kwargs):\n",
    "    cmap = sns.cubehelix_palette(n_colors=24, as_cmap=True, dark=0, light=1)\n",
    "    cmap.set_under('white')\n",
    "    cmap.set_bad('white')\n",
    "    plt.hexbin(x, y, gridsize=40, cmap=cmap, **kwargs)\n",
    "\n",
    "def hist(x, **kwargs):\n",
    "    sns.distplot(x, kde=False)\n",
    "    \n",
    "logDP = np.log1p(variants['DP'])\n",
    "SOR_clip = np.clip(variants['SOR'],a_max=6, a_min=0)\n",
    "ReadPosRankSum_clip = np.clip(variants['ReadPosRankSum'],a_max=5, a_min=-5)\n",
    "MAF = np.nanmax(variants['AF'], axis=1)\n",
    "QD = variants['QD'][:]\n",
    "\n",
    "df_variants = pd.DataFrame({'logDP': logDP, \n",
    "              'SOR_clip': SOR_clip, \n",
    "              'ReadPosRankSum_clip': ReadPosRankSum_clip, \n",
    "              'MAF': MAF,\n",
    "              'QD': QD})\n",
    "\n",
    "g = sns.PairGrid(data=df_variants[variants.is_snp[:]].fillna(0), \n",
    "                 x_vars=['QD', 'logDP', 'MAF', 'SOR_clip', 'ReadPosRankSum_clip'], \n",
    "                 y_vars=['QD', 'logDP', 'MAF', 'SOR_clip', 'ReadPosRankSum_clip'],\n",
    "                 size=4,\n",
    "                 diag_sharey=False)\n",
    "g.map_diag(hist)\n",
    "g.map_lower(hexbin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Â QUAL by Depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def collapse_fancy_index(idx):\n",
    "    '''Takes an array of indics, eg from argsort or lexsort\n",
    "       and collapses runs of consecutive indices into\n",
    "       (start,end) blocks. \n",
    "       \n",
    "       >>>collapse_fancy_index([1,2,3,4,5,10,11,12,13])\n",
    "       [(1, 6), (10, 14)]\n",
    "       '''\n",
    "    blocks = []\n",
    "    curr_start, curr_end = idx[0], idx[0]\n",
    "    for i in idx[1:]:\n",
    "        if i == curr_end + 1:\n",
    "            # Extend current block\n",
    "            curr_end += 1\n",
    "        else:\n",
    "            # start new block\n",
    "            blocks.append((curr_start, curr_end+1))\n",
    "            curr_start, curr_end = i, i\n",
    "    blocks.append((curr_start, curr_end+1))\n",
    "    return blocks\n",
    "\n",
    "def take_collpased_index(blocks, X):\n",
    "    '''Similar to np.take. Performs simple indexing for a list\n",
    "       of (start,end) tuples and concatenates the result'''\n",
    "    if isinstance(X, np.ndarray):\n",
    "        return np.concatenate([X[s:e] for s,e in blocks])\n",
    "    elif isinstance(X, da.Array):\n",
    "        return da.concatenate([X[s:e] for s,e in blocks])\n",
    "    else:\n",
    "        raise Exception(\"X must either a Dask or Numpy array\")\n",
    "\n",
    "QD = da.from_array(variants['QUAL'], chunks=10000)/da.from_array(variants['DP'], chunks=10000)\n",
    "rQD = take_collpased_index(collapse_fancy_index(np.where(~is_snp)[0]), QD)                                                   \n",
    "vQD = take_collpased_index(collapse_fancy_index(np.where(is_snp)[0]), QD)                                                   \n",
    "\n",
    "\n",
    "with ProgressBar():\n",
    "    rQD = rQD.compute(num_workers=NCPU)\n",
    "    vQD = vQD.compute(num_workers=NCPU)\n",
    "    \n",
    "vQD = np.nan_to_num(vQD)\n",
    "rQD = np.nan_to_num(rQD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(ncols=2,nrows=1)\n",
    "\n",
    "sns.distplot(vQD[vQD > 0], kde=False, ax=ax.flat[0])\n",
    "sns.distplot(rQD[rQD > 0], kde=False, ax=ax.flat[1])\n",
    "\n",
    "ax.flat[0].set_yscale('log')\n",
    "ax.flat[0].set_title('Variants')\n",
    "ax.flat[0].set_ylabel(\"Sites\")\n",
    "ax.flat[0].set_xlabel(\"QUAL/DP\")\n",
    "\n",
    "ax.flat[1].set_yscale('log')\n",
    "ax.flat[1].set_title('Non-variants')\n",
    "ax.flat[1].set_xlabel(\"QUAL/DP\")\n",
    "\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Depth Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DP = da.from_array(callset['calldata/DP'], chunks=(100000, 1))\n",
    "with ProgressBar():\n",
    "    DPmax = DP.max().compute(num_workers=NCPU)\n",
    "counted_ = [da.bincount(DP[:,i], minlength=DPmax+1) for i, _ in enumerate(samples)]\n",
    "counted = ([b.compute(num_workers=NCPU) for b in counted_])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def log_bin(X, a, start=1):\n",
    "    # Create the bins\n",
    "    j_max = int(np.ceil(np.log(np.max(X))/np.log(a)))\n",
    "    widths = [a**j for j in range(j_max)]\n",
    "    bins = np.cumsum([start] + widths)\n",
    "    \n",
    "    # Integerisation\n",
    "    lefts, rights = np.ceil(bins[:-1]), np.floor(bins[1:])\n",
    "    int_width = rights - lefts + 1\n",
    "    centres = np.sqrt(lefts*rights)\n",
    "    \n",
    "    # Distribute\n",
    "    indices = np.digitize(X, bins)\n",
    "    counts = np.zeros_like(centres)\n",
    "    for i in indices:\n",
    "        if i!=0:\n",
    "            # Drop anything dropping of the left side\n",
    "            counts[i-1]+=1  \n",
    "    return centres, counts/(int_width*len(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "for c in counted:\n",
    "    plt.plot(*log_bin(c, 1.75), '-', alpha=0.1,color='blue')\n",
    "plt.loglog()\n",
    "plt.xlabel(\"Read Depth\")\n",
    "plt.ylabel(\"Probability\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INDEL Lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sns.distplot(np.max(variants['svlen'], axis=1), kde=False)\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
