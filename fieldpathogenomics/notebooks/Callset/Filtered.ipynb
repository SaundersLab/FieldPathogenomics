{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##luigi-vars\n",
    "FILTERED_HD5 = '/nbi/Research-Groups/JIC/Diane-Saunders/FP_project/FP_pipeline/PST130/data/0.3/Callset/2013/2013_filtered.hd5'\n",
    "NCPU = 1\n",
    "MEM_PER_CPU = 1e9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import vcfnp\n",
    "import numpy as np\n",
    "import h5py\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import allel\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from collections import Counter\n",
    "\n",
    "import dask\n",
    "import dask.array as da\n",
    "from dask.distributed import Client, LocalCluster, progress\n",
    "\n",
    "import bootstrapped.bootstrap as bootstrap\n",
    "from bootstrapped.stats_functions import mean\n",
    "\n",
    "from fieldpathogenomics.utils import reference_dir, index_variants\n",
    "\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12,6)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lc = dask.distributed.LocalCluster(n_workers=NCPU, threads_per_worker=1, memory_limit=MEM_PER_CPU)\n",
    "client = Client(lc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callset = h5py.File(FILTERED_HD5, mode='r')\n",
    "calldata = callset['calldata']\n",
    "genotypes = allel.GenotypeDaskArray(callset['calldata']['GT'])\n",
    "samples = np.array(callset['samples']).astype('U')\n",
    "variants = allel.VariantChunkedTable(callset['variants'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_variants = genotypes.shape[0]\n",
    "n_samples = genotypes.shape[1]\n",
    "\n",
    "pc_missing = genotypes.count_missing(axis=0) * 100 / n_variants\n",
    "pc_het = genotypes.count_het(axis=0) * 100 / n_variants\n",
    "pc_miss_per_site =  genotypes.count_missing(axis=1) * 100/ n_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "pc_missing, pc_het, pc_miss_per_site = da.compute(pc_missing, pc_het, pc_miss_per_site)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Mapping Statistics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "connection_string = \"mysql+pymysql://tgac:tgac_bioinf@tgac-db1.hpccluster/buntingd_fieldpathogenomics\"\n",
    "df = pd.read_sql('AlignmentStats', connection_string).apply(pd.to_numeric, args=('ignore',)).drop_duplicates()\n",
    "df = df.drop_duplicates()\n",
    "df.set_index(\"Library\").loc[samples].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select from database the only most relevant mapping statistics\n",
    "path = ''\n",
    "for p in df['path']:\n",
    "    if len(os.path.commonprefix((p, FILTERED_HD5))) >  len(path):\n",
    "        path = os.path.commonprefix((p, FILTERED_HD5))\n",
    "df = df[df['path'].str.slice(0, len(path)) == path]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 9))\n",
    "sns.distplot(pc_missing, ax=plt.subplot(311))\n",
    "sns.distplot(pc_miss_per_site, ax=plt.subplot(312))\n",
    "sns.distplot(df.set_index(\"Library\").loc[samples]['mapped_reads'], ax=plt.subplot(313))\n",
    "\n",
    "\n",
    "plt.subplot(312).set_xlabel(\"Frac missing\")\n",
    "plt.subplot(311).set_xlabel(\"Frac missing\")\n",
    "plt.subplot(312).set_title(\"Per Site\", fontsize=24)\n",
    "plt.subplot(311).set_title(\"Per Library\", fontsize=24)\n",
    "plt.subplot(313).set_title(\"Mapped Reads\", fontsize=24)\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Site and Sample Coverage Thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "percentiles, N80, Nbases, het_rates, het_std = [], [], [], [], []\n",
    "sample_cov = np.linspace(100-pc_missing.max(), 100-pc_missing.min(), 10)\n",
    "site_thresholds = np.linspace(0.1, 0.9, 9)\n",
    "\n",
    "site_coverage, site_het, site_called = [], [], []\n",
    "\n",
    "for i,x in enumerate(sample_cov):\n",
    "    # Apply a filter at min sample coverage x\n",
    "    filtered = genotypes[:, pc_missing <= (100 - x)]\n",
    "    \n",
    "    # Calculate site level statistics at this filter level\n",
    "    site_called.append(filtered.count_called(axis=1))\n",
    "    site_coverage.append(site_called[i]/filtered.shape[1])\n",
    "    site_het.append(filtered.is_het().sum(axis=1)/site_called[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "site_called = client.persist(site_called)\n",
    "site_coverage = client.persist(site_coverage)\n",
    "site_het = client.persist(site_het)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "for i,x in enumerate(sample_cov):\n",
    "    # Summerise site level stats\n",
    "    percentiles.append(da.percentile(site_coverage[i], np.linspace(0, 100, 20)))\n",
    "    Nbases.append( da.stack([site_called[i][site_coverage[i] > t].sum() for t in site_thresholds]) )\n",
    "    N80.append((site_coverage[i] > 0.8).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time\n",
    "futures = client.compute((percentiles, N80, Nbases), optimize_graph=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "het_rates = []\n",
    "for i,x in enumerate(sample_cov):\n",
    "    het = [site_het[i][site_coverage[i] > t] for t in site_thresholds]\n",
    "    het_rates.append( [dask.delayed(bootstrap.bootstrap)(h, mean, num_iterations=100, iteration_batch_size=1) for h in het])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "het_futures = client.compute(het_rates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percentiles, N80, Nbases = client.gather(futures)\n",
    "het_rates = client.gather(het_futures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2,2)\n",
    "ax1,ax2,ax3,ax4 = ax.flatten()\n",
    "fig.set_size_inches((16, 12))\n",
    "\n",
    "ax1.plot(100-np.sort(pc_missing), np.arange(len(pc_missing)), '.')\n",
    "ax1.set_xlabel(\"Sample minimum Coverage %\")\n",
    "ax1.set_ylabel(\"Number of accepted samples\")\n",
    "\n",
    "ax2.plot(sample_cov, N80, '.-')\n",
    "ax2.set_xlabel(\"Sample minimum Coverage %\")\n",
    "ax2.set_ylabel(\"N sites at >80% coverage\");\n",
    "\n",
    "pal = sns.cubehelix_palette(len(site_thresholds), start=0.5, rot=-1)\n",
    "for i, t in enumerate(site_thresholds):\n",
    "    ax3.plot(sample_cov, np.array(Nbases)[:,i], '.-', label = str(t), color=pal[i])\n",
    "    ax4.errorbar(x=sample_cov, y=[x.value for x in np.array(het_rates)[:,i]],\n",
    "                 yerr=np.transpose([[x.value-x.lower_bound, x.upper_bound-x.value] for x in np.array(het_rates)[:,i]]),\n",
    "                 fmt='.-', label = str(t), color=pal[i], capsize=10, capthick=3)\n",
    "\n",
    "ax3.set_xlabel(\"Sample minimum Coverage %\")\n",
    "ax3.set_ylabel(\"Bases Called\");\n",
    "ax3.legend(loc='best', title=\"Min site coverage\")\n",
    "\n",
    "ax4.set_xlabel(\"Sample minimum Coverage %\")\n",
    "ax4.set_ylabel(\"Heterozygosity\");\n",
    "#ax4.legend(loc='best', title=\"Min site coverage\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18,8))\n",
    "\n",
    "ax1 = plt.subplot(121)\n",
    "pal = sns.cubehelix_palette(len(sample_cov), start=.5, rot=-.75)\n",
    "\n",
    "for i, (x, p) in enumerate(zip(sample_cov[:-2], percentiles[:-2])):\n",
    "    ax1.plot(p, 100-np.linspace(0, 100, 20), '.-', \n",
    "             label=\"coverage {0:.1f}%, {1} samples \".format(x, np.sum(pc_missing <= (100 - x))), \n",
    "             color=pal[i])\n",
    "\n",
    "\n",
    "ax2 = plt.subplot(122)    \n",
    "for i, t in enumerate(sample_cov[:-2]):\n",
    "    ax2.errorbar(x=site_thresholds, y=[x.value for x in np.array(het_rates)[i]],\n",
    "                 yerr=np.transpose([[x.value-x.lower_bound, x.upper_bound-x.value] for x in np.array(het_rates)[i]]),\n",
    "                 fmt='.-', label = str(t), color=pal[i], capsize=10, capthick=3)\n",
    "\n",
    "ax2.set_xlabel(\"Min site Coverage %\")\n",
    "ax2.set_ylabel(\"Heterozygosity\");\n",
    "\n",
    "ax1.legend(loc='best', title='Sample Coverage')\n",
    "ax1.set_xlabel(\"Min Site Coverage\")\n",
    "ax1.set_ylabel(\"Percent sites at min coverage\")"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Called sites vs Mapped reads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18,8))\n",
    "\n",
    "plt.subplot(121).plot(df.set_index(\"Library\").loc[samples]['mapped_reads_pc'], 100-pc_missing, '.')\n",
    "plt.subplot(121).set_xlabel(\"% reads mapped\")\n",
    "plt.subplot(121).set_ylabel(\"% sites called\")\n",
    "\n",
    "plt.subplot(122).plot(df.set_index(\"Library\").loc[samples]['mapped_reads'], 100-pc_missing, '.')\n",
    "plt.subplot(122).set_xlabel(\"Mapped reads\")\n",
    "plt.subplot(122).set_ylabel(\"% sites called\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
